---
title: "[Data Structure] CS 스터디 1주차"
excerpt: "시간복잡도, 공간복잡도, 링크드 리스트, 스택, 큐, 해시, 트리, 힙, 정렬"

categories:
  - data-structure
tags:
  - [sort]

toc: true
toc_sticky: true

sidebar:
  nav: "categories"

date: 2023-12-02
last_modified_at: 2023-12-05
---

> [깃허브 인터뷰 레포지토리](https://github.com/VSFe/Tech-Interview)에 있는 질문들을 가지고 매주 토론하는 스터디를 진행 중입니다.

# 1주차

## 시간복잡도, 공간복잡도

- **시간복잡도와 공간복잡도에 대해 설명해 주세요.**
    - 시간복잡도
        - 특정 알고리즘이 어떤 문제를 해결하는 데 걸리는 시간
    - 공간복잡도
        - 작성한 프로그램이 얼마나 많은 공간(메모리)를 차지하느냐를 분석하는 방법
- Big-O, Big-Theta, Big-Omega 에 대해 설명해 주세요.
    - Big-O
        - 점근적 상한 표기 (증가율이 같거나 더 낮은 함수들의 집합)
        - ex) $2n^3 + 3n^2 - 25 \notin O(n^2)$
        - ex) $10n^2 + 3n - 25 \in O(n^2)$
    - Big-Omega
        - 점근적 하한 표기 (증가율이 같거나 더 높은 함수들의 집합)
        - ex) $2n^3 + 3n^2 - 25 \in \Omega(n^2)$
        - ex) $10n^2 + 3n - 25 \in \Omega(n^2)$
    - Big-Theta
        - Big-O와 Big-Omega의 표기가 같은 경우에 사용
        - ex) $2n^3 + 3n^2 - 25 \notin \theta(n^2)$
        - ex) $10n^2 + 3n - 25 \in \theta(n^2)$
- 다른 것을 사용하지 않고, Big-O를 사용하는 이유가 있을까요?
    - 알고리즘 효율성을 상한선 기준으로 표기하기 때문
        - 알고리즘 효율성은 값이 클수록, 즉 그래프가 위를 향할수록 비효율적임
- $O(1)$은 $O(N^2)$ 보다 무조건적으로 빠른가요?
    - 입력의 수에 따라서 $O(N^2)$도 $O(1)$보다 빨라질 수 있다.
    - 입력 크기가 작으면 $O(N^2)$의 알고리즘보다  $O(1)$의 알고리즘이 더 느릴 수 있다.

## 링크드 리스트

- **링크드 리스트에 대해 설명해 주세요.**
    - 링크드 리스트
        - 노드를 포인터로 연결하여 구현하는 리스트
        - 종류로는 단일 연결 리스트, 이중 연결 리스트, 원형 연결 리스트가 있음
            - 이중 연결 리스트
                - 단일 연결 리스트에 바로 전의 노드를 가리키는 `previous` 포인터를 추가한 연결 리스트
            - 원형 연결 리스트
                - 마지막 `next` 포인터가 연결 리스트의 노드를 가리키는 연결 리스트
- 일반 배열과, 링크드 리스트를 비교해 주세요.
    - 일반 배열
        - 연속적인 메모리 공간상에 있으며, 인덱스를 이용한 접근이 $O(1)$로 빠름
        - 하지만 삽입과 삭제 연산의 경우, 배열의 데이터를 이동시켜야 하기 때문에 $O(N)$의 시간으로 수행됨
        - 메모리 할당: 컴파일
    - 링크드 리스트
        - 연속적인 메모리 공간에 존재하지 않고, 포인터로 연결되어 있기 때문에 노드를 순차적으로 접근
        - 하지만 배열과 달리, 크기에 대한 제약이 없음
        - 또한 삽입, 삭제 연산이 $O(1)$의 시간으로 수행됨
        - 메모리 할당: 런타임
- 링크드 리스트를 사용해서 구현할 수 있는 다른 자료구조에 대해 설명해 주세요.
    - 배열로 대부분의 자료구조는 구현 가능
    - 대표적으로 스택과 큐가 있음

## 스택, 큐

- **스택과 큐에 대해서 설명해 주세요.**
    - 스택
        - Last In First Out을 하는 자료구조
        - 한 번 들어간 요소들은 나올 때 순서가 **reverse** 되어 나옴
    - **큐**
        - First In First Out을 하는 자료구조
        - 한 번 들어간 요소들은 나올 때 들어간 **순서대로** 나옴
        - add, remove, peek → 큐가 비어있을 때 null pointer 에러 발생
    - 포인터로 알기
- 스택 2개로 큐를, 큐 2개로 스택을 만드는 방법과, 그 시간복잡도에 대해 설명해 주세요.
    - 스택 2개로 큐 만들기
        - 삽입 연산
            - `stack1`로는 데이터 push
        - 삭제 연산
            - `stack2`로는 데이터 pop
            - 이때 `stack2`의 데이터가 비어있다면, `stack1`에서 `stack2`로 데이터 이동
        - 시간 복잡도
            1. `stack2`가 비어있을 때 pop
                - $O(N)$
            2. `stack2`가 비어있지 않을 때 pop, push
                - $O(1)$
    - 큐 2개로 스택 만들기
        - 삽입 연산
            - `queue2`에 데이터 push
            - 만약 `queue2` 에 데이터가 있다면, `queue1` 기존 데이터를 push
        - 삭제 연산
            - `queue2` 에 데이터가 있는 경우
                - `queue2` 데이터 pop
            - `queue2` 에 데이터가 없는 경우
                - `queue2` 에 `queue1` 의 데이터가 하나 남을 때까지 이동 후 그 마지막 데이터를 pop
                - `queue2` 에 데이터가 하나 남을 때까지 데이터를 `queue1` 로 이동
        - 시간 복잡도
            - push, `queue2` 에 데이터가 있을 경우 pop
                - $O(1)$
            - `queue2` 에 데이터가 없을 경우 pop
                - $O(N)$
- 시간복잡도를 유지하면서, 배열로 스택과 큐를 구현할 수 있을까요?
    - 스택
        - 어떤 상황에서든 가능
    - 큐
        - 배열의 빈 공간을 미리 확보 후, 배열의 중간부터 큐의 head를 시작한다면 가능
        - 하지만 빈 공간보다 더 많은 수의 데이터가 삽입될 시, 더 많은 시간이 걸릴 가능성이 있음
- Prefix, Infix, Postfix 에 대해 설명하고, 이를 스택을 활용해서 계산/하는 방법에 대해 설명해 주세요.
    - Prefix (전위표기법)
        - `+AB`
        - 연산자를 먼저 표시하고, 연산에 필요한 피연산자를 나중에 표기하는 방법
        - 연산자를 만나면 push
        - 연속 두 개의 피연산자를 만날 시 pop
    - Infix (중위표기법)
        - `A+B`
        - 연산자를 두 피연산자 사이에 표기하는 방법으로, 가장 일반적으로 사용되는 표현 방법
    - Postfix (후위표기법)
        - `AB+`
        - 피연산자를 먼저 표기하고 연산자를 나중에 표기하는 방법
            - 컴파일러가 사용하는 것으로, 스택을 사용하는 예들 중 가장 빈번하게 등장함
        - 피연산자를 만나면 push
        - 연산자를 만나면 pop
- Deque는 어떻게 구현할 수 있을까요?
    - Deque 자료구조는 Stack과 Queue의 특성을 모두 갖는 자료구조
    - 원형 큐를 확장하게 구현
    - 나머지 연산들은 원형 큐와 같고, `delete_rear()` , `add_front()` 에서 rear와 front를 반대 방향으로 회전시키면 됨

```python
front = (front - 1 + MAX_SIZE) / MAX_SIZE
rear = (rear - 1 + MAX_SIZE) / MAX_SIZE
```

## 해시

- **해시 자료구조에 대해 설명해 주세요.**
    - 해시
        - 여러 길이의 데이터를 효율적으로 관리하기 위해 해시 함수를 통해 일정한 길이의 값으로 매핑하는 것
        - 연결 리스트의 단점은 리스트에서 무언가를 찾고 싶을 때 무조건 모든 요소를 살펴봐야 한다는 점인데, 이러한 단점을 해결하여 데이터를 빠르게 추가하거나 제거하도록 한 데이터 구조
- 값이 주어졌을 때, 어떻게 하면 충돌이 최대한 적은 해시 함수를 설계할 수 있을까요?
    - sha 256
    - Division Method
        - 값을 버킷 사이즈로 나누어 나머지를 전체 버킷 사이즈에서 뺀 값으로 사용
        - 이 때 버킷 사이즈는 소수를 사용하고, 2의 제곱수와 먼 값을 사용하는 것이 좋음
    - Digit Folding
        - 값이 문자열일 때 아스키 코드로 바꿔 합한 값을 사용
        - 이때 버킷 사이즈를 넘어갈 수 있기 때문에 Division Method를 함께 사용
    - Multiplication Method
        - `floor(K*A mod 1) * m` 의 식을 사용
            - `mod` 는 나머지를 계산하는 연산자
        - A는 0과 1 사이의 실수, m은 2의 제곱수를 사용
    - Universal Hashing
        - 여러 해시 함수를 무작위로 사용
- 해시값이 충돌했을 때, 어떤 방식으로 처리할 수 있을까요?
    - 해시 충돌
        - 서로 다른 값을 가진 키가 일치하는 경우
    - Chaining
        - 요소마다 연결 리스트를 만들어 수많은 데이터를 수용할 수 있게 하는 방법
        - 체인 해시는 가장 안정적이고 보편적으로 사용되는 자료 구조 중 하나
        - 체이닝을 하면 수용 가능한 요소 개수에 제한이 없어지고 크기 조정도 자주 할 필요가 없어짐
        - 적재율 λ는 항목의 개수를 가능한 체인 개수로 나눈 값
            - 체인 1개에 여러 항목을 넣을 수 있어 λ는 1보다 큰 수가 될 수 있음
                - 하지만 hashCode가 같은 숫자만 반환하여 하나의 체인이 너무 길어지면 결국 연결 리스트와 시간 복잡도가 같아지는 문제가 발생함
    - Open Addressing
        - Open Addressing
            - 인덱스가 중복되었다면 다른 빈 인덱스를 찾아 저장하는 방법
        1. 선형 조사법 (linear probing)
            - 채우려는 공간이 이미 차 있다면, 비어있는 칸을 찾을 때까지 다음 칸을 확인하는 방법
            - 비어있는 칸을 찾아 그 곳에 채운 후 위치가 바뀌었다는 사실을 알려야 함
        2. 2차식 조사법 (quadratic probing)
            - 다음 칸 대신 1부터 순서대로 제곱하여 더한 칸(12,22,…)(12,22,…)을 확인하는 방법
            - 테이블의 끝을 넘어간다면 % 연산을 해서 다시 테이블의 범위 안에 들어오게 함
        3. 이중 해싱 (double hashing)
            - hashCode 함수가 2개 있어 채우려는 공간이 이미 차 있다면 두 hashCode의 결과를 더한 값을 테이블 내의 위치가 되게 하는 방법
        - 이중 해싱은 아예 다른 해시 함수를 사용할 수 있기 때문에 데이터를 더 골고루 넣을 수 있음
            - 하지만 해시 함수가 2개 필요하다는 단점이 존재함
        - 선형 조사법과 2차식 조사법은 더하는 값(1, 2, 3, … 또는 1^2, 2^2, 3^2, …)에 규칙성이 있는 반면에
            - 이중 해싱은 두번째 해시 함수가 리턴하는 값이 임의적이기 때문에 배열의 더 다양한 위치에 값을 저장할 수 있음
- 본인이 사용하는 언어에서는, 어떤 방식으로 해시 충돌을 처리하나요?
    - Java
        - jdk 7까지는 링크드 리스트를 사용한 sepearte chaining을 활용
        - jdk 8에서 링크드 리스트와 red black tree를 혼용한 separate chaining을 활용
            - 충돌을 한 key-value 쌍이 적을 때는 링크드 리스트로 작동
            - 충돌을 한 key-value 쌍이 특정 임계치에 도달하면 red black tree로 작동
            - 결론: 링크드 리스트는 탐색하는 데 시간 복잡도가 $O(N)$의 비용이 드는 반면에, red black tree는 $O(logN)$의 비용이 들기 때문에 jdk 8에서는 성능적으로 개선이 되었다고 볼 수 있음
- Double Hashing 의 장점과 단점에 대해서 설명하고, 단점을 어떻게 해결할 수 있을지 설명해 주세요.
    - Double Hashing
        - 개방 주소법 중 하나
        - 충돌이 발생한 버킷에 다른 버킷의 데이터를 저장하는 방식
        - 두 개의 해시 함수를 이용하여 다음 이동 위치를 결정하는 방식으로, 충돌 해결에 유용
    - 장점
        - 해시 테이블의 공간 사용을 최소화하고, 버킷들 사이의 균형을 맞추어 해시 충돌을 감소시킬 수 있음
    - 단점
        - 해시 함수의 선택이 중요하며, 잘못된 해시 함수 선택 시 일정한 패턴으로 충돌이 발생하여 클러스터링 현상이 발생할 수 있음
            - 클러스터
                - 해시 함수가 내뱉는 해시 값들이 저장 공간 한 쪽에 뭉치게 되는 경우, 저장 공간을 온전히 잘 활용해서 쓴다고 볼 수 없음
                - 예를 들어, 저장 공간이 0에서 100까지 있는데, 해시 함수가 30에서 50의 값 위주로 해싱한다면, 0~29과 51~100의 공간은 쓰이지 않게 낭비되게 됨
                - 이렇게 뭉쳐 있는 현상을 클러스터라고 하며, 클러스터 현상이 없을수록 좋은 해시 테이블이라 할 수 있음
        - 이를 해결하기 위해서는 두 개의 해시 함수를 서로 독립적으로 선택하고, 충돌이 발생한 경우에 대한 처리 방법을 세밀하게 조정하는 등의 조치를 취할 수 있음

## 다섯번째

- **트리와 이진트리, 이진탐색트리에 대해 설명해 주세요.**
    - 트리
        - 노드와 간선으로 이루어져 있는 구조
        - 사이클이 없고 노드의 개수가 N 개라면 간선의 개수는 N-1 개를 가지는 구조
    - 이진 트리
        - 각각의 노드가 자식 노드를 최대 2개 가지는 트리
    - 이진 탐색 트리
        - 이진 트리 중 중복이 없고, 왼쪽 자식 노드는 루트보다 작고, 오른쪽 자식 노드는 루트보다 큰 값을 가지는 구조
- 그래프와 트리의 차이가 무엇인가요?
    - 트리는 그래프의 일종임
    - 하지만 트리는 그래프와 달리 방향성을 가지고, 사이클이 존재하지 않음
- 이진탐색트리에서 중위 탐색을 하게 되면, 그 결과는 어떤 의미를 가지나요?
    - 오름차순의 형태가 나옴
    - 이 이진 탐색 트리의 정렬된 순서를 읽을 수 있음
- 이진 탐색 트리의 주요 연산에 대한 시간복잡도를 설명하고, 왜 그런 시간복잡도가 도출되는지 설명해 주세요.
    - 삽입
        - 삽입이 될 위치를 찾아야 되기 때문에 탐색과 동일하게 $O(logN)$
    - 삭제
        - 삭제할 노드를 탐색하고, 만약 삭제된 자리를 대체하기 위한 노드를 찾아야 한다면 다시 탐색을 수행
        - 즉, 다른 연산들과 동일하게 $O(logN)$
    - 탐색
        - 최악의 경우 트리의 높이만큼 탐색하기 때문에 $O(logN)$
        - 하지만 이 경우는 포화 트리일 경우이고, 편향 트리일 경우에는 $O(N)$
- 이진 탐색 트리의 한계점에 대해 설명해주세요.
    - 모든 연산이 트리의 높이에 의해 결정이 되기 때문에, 편향 트리일 경우 이진 탐색 트리의 장점을 살릴 수 없음
    - 이런 경우 때문에 AVL 트리 같은 개선된 트리가 나오게 됨
- 이진 탐색 트리의 값 삽입, 삭제 방법에 대해 설명하고, 어떤식으로 값을 삽입하면 편향이 발생할까요?
    - 삽입
        - 탐색하여 탐색을 실패한 자리에 값 삽입
    - 삭제
        - 삭제하려는 노드가 리프일 경우 그냥 삭제
        - 삭제하려는 노드가 하나의 서브 트리만 가지고 있는 경우, 삭제된 노드를 부모 노드에 연결
        - 삭제하려는 노드가 두 개의 서브 트리를 가질 경우, 왼쪽 서브 트리에서 가장 큰 자손을 올리거나 오른쪽 서브 트리에서 가장 작은 자손을 올림

## 여섯번째

- **힙에 대해 설명해 주세요.**
    - 힙
        - 완전 이진 트리의 일종으로 반정렬 상태를 유지하여 최대 혹은 최소의 값을 빠르게 반환할 수 있는 자료구조
        - 주로 우선 순위 큐를 구현하기 위해 이용됨
        - 이진 탐색 트리의 단점을
- 힙을 배열로 구현한다고 가정하면, 어떻게 값을 저장할 수 있을까요?
    - 힙은 대체적으로 배열로 구현됨
        - 완전 이진 트리를 기본으로 하기 때문에 빈 공간이 없어 배열로 구현하기 용이함
    - 아래 그림과 같이 루트 노드를 배열의 0번 index에 저장하고, 각 노드를 기점으로 왼쪽 자식 노드는 a[i * 2 + 1], 오른쪽 자식 노드는 a[i * 2 + 2]의 index에 저장됨
    - 또한 특정 index의 노드에서 부모 노드는 a[(i - 1) // 2]로 찾을 수 있음

![https://velog.velcdn.com/images%2Femplam27%2Fpost%2F4a05c33e-2caf-4b28-964c-7019c13ff34b%2F%ED%9E%99%20-%20%EB%B0%B0%EC%97%B4%EB%A1%9C.png](https://velog.velcdn.com/images%2Femplam27%2Fpost%2F4a05c33e-2caf-4b28-964c-7019c13ff34b%2F%ED%9E%99%20-%20%EB%B0%B0%EC%97%B4%EB%A1%9C.png)

- 힙의 삽입, 삭제 방식에 대해 설명하고, 왜 이진탐색트리와 달리 편향이 발생하지 않는지 설명해 주세요.
    - 삽입
        - 맨 마지막 자리에 요소를 삽입 후, 힙의 속성에 맞을 때까지 부모와 자식간의 교환을 함
    - 삭제
        - 루트 노드와 맨 마지막 요소를 스왑한 후 마지막 요소를 반환
        - 그 후 힙의 속성에 맞을 때까지 부모와 자식간의 교환을 함
    - 편향이 발생하지 않는 이유
        - 이진 탐색 트리에서 편향이 발생하려면 완전 정렬된 상태로 삽입이 이루어져야 함
        - 하지만 이때 힙은 최대 혹은 최소 요소를 루트 노드로 하는 완전 이진 트리를 유지하도록 삽입 및 삭제를 하기 때문에 편향이 발생하지 않음
- 힙 정렬의 시간복잡도는 어떻게 되나요? Stable 한가요?
    - 힙 정렬의 시간 복잡도는 힙을 구성하고 나서 삭제 연산을 반복하면 되므로 $O(NlogN)$임
    - Unstable함

## 일곱번째

- **BBST (Balanced Binary Search Tree) 와, 그 종류에 대해 설명해 주세요.**
    - 이진 탐색 트리의 단점을 보완한 트리
    - 편향 트리가 발생하지 않도록 삽입 혹은 삭제를 할 때 높이의 균형을 유지하는 트리
    - 그 종류로는 AVL, red black tree, B tree, B+ tree 등이 있음
- Red Black Tree는 어떻게 균형을 유지할 수 있을까요?
    - 조건
        1. 모든 노드는 빨강 혹은 검정
        2. 루트 노드는 검정
        3. 모든 리프는 검정
        4. 빨강 노드의 자식은 검정
        5. 모든 리프 노드에서 black depth는 동일
        - 리프 노드에서 루트 노드까지 가는 경로에서 만나는 검정 노드의 개수가 같음
    - 삽입
    - 삭제
- Red Black Tree의 주요 성질 4가지에 대해 설명해 주세요.
    1. 루트 노드는 검정
    2. 모든 리프는 검정
    3. 빨강 노드의 자식은 검정
    4. 모든 리프 노드에서 black depth는 동일
- 2-3-4 Tree, AVL Tree 등의 다른 BBST가 있음에도, 왜 Red Black Tree가 많이 사용될까요?
    - Red Black Tree
        - 삽입, 삭제 작업 시 균형을 맞추기 위한 작업 횟수가 적음
        - 각 노드당 색을 표현하는 데 단 1 bit의 저장 공간만 필요
        - 언제 회전에 의해 균형을 잡아야 하는지가 쉽게 판별됨
        - 이진 탐색 트리의 함수를 거의 그대로 사용함
    - AVL Tree
        - 조회 시 더 빠른 성능을 자랑함
        - 노드에 색이 없음
        - 빠르지만 재균형 잡는 시간이 듦
        - 프로그래밍과 디버깅이 어려움
        - Balance Factor를 이용해 밸런스를 유지
            - 모든 노드의 BF가 -1, 0, 1 중 하나여야 함
        - `BF(K) = K의 왼쪽 서브 트리의 높이 - 오른쪽 서브 트리의 높이`
    - 2-3-4 Tree
        - 2 노드, 3 노드, 4 노드가 있는 균형 탐색 트리
            - n 노드란 n - 1개의 키와 n 개의 자식을 가지고 있다는 의미
        - 한 노드의 한 키의 왼쪽 부분 트리에 있는 모든 키 값은 그 키 값보다 작고, 오른쪽 부분 트리에 있는 모든 키 값은 그 키 값보다 커야 함
        - 모든 리프 노드의 높이는 동일
        - 삽입 연산은 4 노드에서 스플릿 연산이 이루어짐
        - 노드 구조가 복잡함
        - 삽입 삭제 코드가 복잡함

## 여덟번째

- **정렬 알고리즘에 대해 설명해 주세요.**
    - 정렬 알고리즘
        - 어떠한 자료구조를 정렬하는 방법
        - Quick Sort, Merge Sort, Radix Sort, Counting Sort, Bubble Sort, Insertion Sort, Selection Sort 등이 있음
- Quick Sort와 Merge Sort를 비교해 주세요.
    - Quick Sort
        - pivot을 기준으로 나눠 정렬하는 기법
    - Merge Sort
        - 자료구조를 분할 후에 합치면서 정렬하는 방법
    - Merge Sort는 최악, 평균, 최선일 경우 모든 $O(nlogN)$의 시간이 소요되는 반면, Quick Sort는 역순으로 정렬되어 있을 시 pivot의 효과를 볼 수 없기 때문에 최악의 경우 $O(n^2)$의 시간이 소요됨
- Quick Sort에서 O(N^2)이 걸리는 예시를 들고, 이를 개선할 수 있는 방법에 대해 설명해 주세요.
    - 오름차순 혹은 내림차순으로 정렬되어 파티션이 나뉘지 않는 경우
    - 이를 개선하기 위해서는 중간값과 맨앞값을 서로 스왑해주면 어느 정도의 개선이 가능
- Stable Sort가 무엇이고, 어떤 정렬 알고리즘이 Stable 한지 설명해 주세요.
    - Stable Sort
        - 중복된 값이 있을 시 이 순서가 변경되지 않는 정렬을 의미
        - Insertion Sort, Merge Sort, Bubble Sort, Counting Sort가 Stable 함
- Merge Sort를 재귀를 사용하지 않고 구현할 수 있을까요?
    - 큐를 이용하여 구현할 수 있음
- Radix Sort에 대해 설명해 주세요.
    - Radix Sort
        - 자릿수를 이용해 정렬을 하는 정렬 기법
        - 0~9에 해당하는 버킷을 만들고, 낮은 자릿수부터 진행하며, 순서대로 해당하는 자릿수의 버킷에 요소를 저장하고 정렬시키는 과정을 반복하여 정렬하는 기법
    - 시간 복잡도
        - $O(dN)$
            - `d` : 자릿수
- Bubble, Selection, Insertion Sort의 속도를 비교해 주세요.
    - 시간 복잡도는 모두 $O(N^2)$
- 값이 **거의** 정렬되어 있거나, 아예 정렬되어 있다면, 위 세 알고리즘의 성능 비교 결과는 달라질까요?
    - Selection Sort는 정렬되어 있을 시 비교 연산만 하기 때문에 $O(N^2)$가 아니라 $O(N)$의 시간 복잡도를 가짐
- 본인이 사용하고 있는 언어에선, 어떤 정렬 알고리즘을 사용하여 정렬 함수를 제공하고 있을까요?
    - Java
        - `Arrays.sort()`
            - Dual-Pivot Quick Sort 사용
            - 일반적인 Quick Sort와는 다르게 pivot을 2개를 두고 3개의 구간을 만들어 Quick Sort를 진행함
            - 랜덤 데이터에 대해서 평균적으로 Quick Sort보다 좋은 성능을 냄
        - `Collections.sort()`
            - Tim Sort 사용
                - Tim Sort는 Insertion Sort와 Merge Sort를 결합하여 만든 정렬
                - Java 7부터 Tim Sort를 채택하여 사용하고 있음
        - Arrays를 정렬했을 때와 Collections를 정렬했을 때 사용하는 알고리즘이 다른 이유
            - 참조 지역성의 원리 때문
                - 참조 지역성의 원리
                    - 동일한 값 또는 해당 값의 근처에 있는 스터리지 위치가 자주 액세스되는 특성
            - 참조 지역성의 원리는 CPU의 캐싱 전략에 영향을 미침
                - 즉, CPU가 데이터를 액세스하며 해당 데이터만이 아니라 인접한 메모리에 있는 데이터 또한 캐시 메모리에 함께 올려둠
- 정렬해야 하는 데이터는 50G 인데, 메모리가 4G라면, 어떤 방식으로 정렬을 진행할 수 있을까요?
    1. 4G만큼 데이터를 메모리에 읽어 일반적인 정렬 알고리즘을 이용해 정렬함
    2. 그러면 13개의 파일이 생김
    3. 280MB씩 각 파일의 앞부분을 읽어옴 (남은 280MB는 출력을 위한 버퍼)
    4. 280MB씩 Merge를 수행하고 출력 버퍼에 작성. 출력 버퍼가 차면 파일에 쓰고 출력 버퍼를 비움. 입력 버퍼가 비워지면 다음 용량만큼 읽음